---
id: ml-training-plan
title: ML Model Training & Fine-Tuning Plan
sidebar_label: ML Training Plan
difficulty: intermediate
estimated_reading_time: 10
points: 15
tags:
  - technical
  - ai
  - counter-uas
---

## Executive Summary

This document provides a comprehensive training and fine-tuning strategy for all
ML models in the Phoenix Rooivalk counter-drone system. The strategy is
optimized for achieving **99.7% threat detection accuracy** with **sub-200ms
inference latency**.

### Key Decisions Summary

| Model       | Approach           | Rationale                       |
| ----------- | ------------------ | ------------------------------- |
| Optical     | Fine-tune          | ImageNet features transfer well |
| RF          | Train from scratch | No suitable pretrained models   |
| Radar       | Train from scratch | Domain-specific sequences       |
| Acoustic    | Fine-tune          | AudioSet contains motor sounds  |
| Fusion      | Train from scratch | Custom architecture             |
| Behavioral  | Train from scratch | Graph structure is unique       |
| Attribution | Train from scratch | Tabular data, fast training     |

### Resource Summary

| Resource     | Specification                                    |
| ------------ | ------------------------------------------------ |
| **Timeline** | 16 weeks                                         |
| **Compute**  | 4Ã— NVIDIA A100 GPUs                              |
| **Budget**   | ~$45,000 (cloud) or 8 weeks (dedicated hardware) |
| **Data**     | 380,000+ labeled samples across all modalities   |

---

## Training vs Fine-Tuning Decision Matrix

### Fundamental Difference

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRAINING FROM SCRATCH                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Random Weights â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Train ALL Layers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Learned Model    â”‚
â”‚        [????]                  (100k+ samples)              [Domain]        â”‚
â”‚                                                                             â”‚
â”‚   â€¢ Model learns EVERYTHING from zero                                       â”‚
â”‚   â€¢ Must learn basic features (edges, textures, patterns)                   â”‚
â”‚   â€¢ Requires massive labeled dataset                                        â”‚
â”‚   â€¢ High compute cost, long training time                                   â”‚
â”‚   â€¢ Full architectural flexibility                                          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              FINE-TUNING                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   Pretrained Model â”€â”€â”€â”€â”€â”€â”€â”€â–º Adapt Layers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Adapted Model    â”‚
â”‚   [ImageNet/AudioSet]        (5k-50k samples)              [Your Domain]   â”‚
â”‚                                                                             â”‚
â”‚   â€¢ Model already knows universal features                                  â”‚
â”‚   â€¢ Only adapts to YOUR specific task                                       â”‚
â”‚   â€¢ Works with smaller datasets                                             â”‚
â”‚   â€¢ Lower compute, faster convergence                                       â”‚
â”‚   â€¢ Risk: catastrophic forgetting                                           â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Decision Criteria

| Criterion                  | Train from Scratch | Fine-Tune |
| -------------------------- | ------------------ | --------- |
| Pretrained model exists?   | No                 | Yes       |
| Domain similarity          | Very different     | Similar   |
| Labeled data available     | 100k+              | 5k-50k    |
| Compute budget             | High               | Limited   |
| Time constraint            | Flexible           | Tight     |
| Custom architecture needed | Yes                | No        |

---

## Progressive Unfreezing Strategy

Progressive unfreezing is the key technique for successful fine-tuning. It
prevents catastrophic forgetting while allowing the model to adapt to your
domain.

### The Problem: Catastrophic Forgetting

When fine-tuning, aggressive training can destroy valuable pretrained knowledge:

```
BEFORE FINE-TUNING (Pretrained on ImageNet):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: [edges âœ“] [colors âœ“] [gradients âœ“]                                â”‚
â”‚ Stage 2: [textures âœ“] [patterns âœ“] [curves âœ“]                              â”‚
â”‚ Stage 3: [shapes âœ“] [parts âœ“] [objects âœ“]                                  â”‚
â”‚ Stage 4: [compositions âœ“] [scenes âœ“] [contexts âœ“]                          â”‚
â”‚ Head:    [ImageNet classes - not useful]                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AFTER AGGRESSIVE FINE-TUNING (High LR on all layers):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: [????? âœ—] [????? âœ—] [????? âœ—]          â† DESTROYED!               â”‚
â”‚ Stage 2: [????? âœ—] [drone?? âœ—] [????? âœ—]        â† DESTROYED!               â”‚
â”‚ Stage 3: [drone âœ“] [bird ~] [????? âœ—]           â† PARTIALLY LOST           â”‚
â”‚ Stage 4: [drone âœ“] [bird âœ“] [aircraft âœ“]        â† LEARNED                  â”‚
â”‚ Head:    [your classes âœ“]                        â† LEARNED                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         Model forgot HOW TO SEE! Only knows drones now.
         Will fail on edge cases, generalization is poor.
```

### The Solution: Progressive Unfreezing Timeline

```
STAGE 1: Train Head Only (Epochs 1-5)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: [FROZEN â„ï¸] edges, colors, gradients           â”‚
â”‚ Stage 2: [FROZEN â„ï¸] textures, patterns                 â”‚
â”‚ Stage 3: [FROZEN â„ï¸] shapes, parts                      â”‚
â”‚ Stage 4: [FROZEN â„ï¸] compositions                       â”‚
â”‚ Head:    [TRAINING ğŸ”¥] LR = 1e-3                        â”‚  â† Only this trains
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Purpose: Learn task-specific classification without
            disturbing any pretrained features.
   Result:  Baseline accuracy ~85-90%


STAGE 2: Unfreeze Last 1-2 Stages (Epochs 6-25)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: [FROZEN â„ï¸] edges, colors, gradients           â”‚
â”‚ Stage 2: [FROZEN â„ï¸] textures, patterns                 â”‚
â”‚ Stage 3: [TRAINING ğŸ”¥] LR = 1e-5    shapes â†’ drone partsâ”‚  â† Adapting
â”‚ Stage 4: [TRAINING ğŸ”¥] LR = 1e-4    comps â†’ drone views â”‚  â† Adapting
â”‚ Head:    [TRAINING ğŸ”¥] LR = 1e-3                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Purpose: Adapt high-level features to drone domain
            while preserving universal low-level features.
   Result:  Accuracy improves to ~94-96%


STAGE 3: Unfreeze All with Differential LR (Epochs 26-50+)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: [TRAINING ğŸ”¥] LR = 1e-7    minimal adjustment  â”‚  â† Tiny updates
â”‚ Stage 2: [TRAINING ğŸ”¥] LR = 1e-6    small refinement    â”‚  â† Small updates
â”‚ Stage 3: [TRAINING ğŸ”¥] LR = 1e-5    moderate tuning     â”‚  â† Medium updates
â”‚ Stage 4: [TRAINING ğŸ”¥] LR = 1e-4    active learning     â”‚  â† Larger updates
â”‚ Head:    [TRAINING ğŸ”¥] LR = 1e-3    most learning       â”‚  â† Most updates
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Purpose: Fine-tune entire network with learning rates
            proportional to how much each layer should change.
   Result:  Final accuracy ~97-99%
```

### Stage-by-Stage Expected Results

| Stage     | Epochs | Trainable Params | Val Accuracy | Training Time |
| --------- | ------ | ---------------- | ------------ | ------------- |
| 1         | 5      | 1.2M (1%)        | 85-88%       | ~2 hours      |
| 2         | 20     | 35M (39%)        | 94-96%       | ~12 hours     |
| 3         | 25-50  | 89M (100%)       | 97-99%       | ~20 hours     |
| **TOTAL** | 50-75  | -                | 97-99%       | ~34 hours     |

---

## Model Training Plans

### Optical Detection (ConvNeXt)

**Training Type**: Fine-tune from ImageNet-22k

#### Data Requirements

| Dataset Component | Quantity     | Source                  |
| ----------------- | ------------ | ----------------------- |
| Commercial drones | 25,000       | Field trials, synthetic |
| Military drones   | 15,000       | Partner data            |
| Birds             | 20,000       | Public datasets, field  |
| Aircraft          | 12,000       | Public datasets         |
| Unknown objects   | 10,000       | Field trials            |
| **Total**         | **100,000+** |                         |

#### Progressive Unfreezing Schedule

| Stage | Epochs | Frozen     | Learning Rate                            | Expected Accuracy |
| ----- | ------ | ---------- | ---------------------------------------- | ----------------- |
| 1     | 5      | Stages 0-3 | Head: 1e-3                               | 85-88%            |
| 2     | 20     | Stages 0-1 | Stage 2: 1e-5, Stage 3: 1e-4, Head: 1e-3 | 94-96%            |
| 3     | 25-50  | None       | Differential 1e-7 to 1e-3                | 97-99%            |

#### Training Configuration

```python
optical_config = {
    "model": "convnext_base.fb_in22k_ft_in1k_384",
    "input_size": (384, 384),
    "batch_size": 32,
    "optimizer": "AdamW",
    "weight_decay": 0.05,
    "label_smoothing": 0.1,
    "mixup_alpha": 0.2,
    "cutmix_alpha": 1.0,
    "gradient_clip": 1.0,
    "precision": "bf16-mixed",
    "augmentation": [
        "RandomResizedCrop",
        "HorizontalFlip",
        "ColorJitter",
        "RandomFog",
        "RandomRain",
        "MotionBlur",
    ]
}
```

### RF Signal Analysis (CNN+Transformer)

**Training Type**: From scratch (no suitable pretrained model)

#### Data Requirements

| Signal Type                | Quantity    | Collection Method    |
| -------------------------- | ----------- | -------------------- |
| WiFi control (2.4/5.8 GHz) | 12,000      | Field SDR capture    |
| Proprietary RF (DJI, etc.) | 10,000      | Field trials         |
| FPV protocols              | 8,000       | Partner data         |
| Military datalink          | 5,000       | Classified sources   |
| Background/interference    | 10,000      | Various environments |
| **Total**                  | **50,000+** |                      |

#### Training Schedule

| Phase     | Epochs | Learning Rate | Notes         |
| --------- | ------ | ------------- | ------------- |
| Warmup    | 5      | 0 â†’ 3e-4      | Linear warmup |
| Main      | 100    | 3e-4 â†’ 1e-6   | Cosine decay  |
| Fine-tune | 50     | 1e-5          | If needed     |

### Radar Track Analysis (Mamba-2)

**Training Type**: From scratch

#### Data Requirements

| Track Type    | Quantity     | Notes               |
| ------------- | ------------ | ------------------- |
| Drone hover   | 30,000       | Stationary patterns |
| Drone transit | 40,000       | Linear movement     |
| Drone evasive | 25,000       | Unpredictable paths |
| Bird single   | 35,000       | Natural flight      |
| Bird flock    | 15,000       | Group behavior      |
| Aircraft      | 20,000       | Fixed patterns      |
| **Total**     | **200,000+** |                     |

### Acoustic Detection (BEATs)

**Training Type**: Fine-tune from AudioSet

#### Data Requirements

| Audio Class         | Quantity    | Duration   |
| ------------------- | ----------- | ---------- |
| Quadcopter small    | 6,000       | 5-15s each |
| Quadcopter large    | 5,000       | 5-15s      |
| Fixed-wing electric | 3,000       | 5-15s      |
| Birds               | 6,000       | 5-15s      |
| Background          | 5,000       | 5-15s      |
| **Total**           | **30,000+** |            |

#### Progressive Unfreezing Schedule

| Stage | Epochs | Frozen Layers           | Learning Rate             |
| ----- | ------ | ----------------------- | ------------------------- |
| 1     | 5      | All encoder (12 layers) | Head: 1e-4                |
| 2     | 15     | First 8 layers          | Last 4: 1e-5, Head: 1e-4  |
| 3     | 30     | None                    | Differential 1e-6 to 1e-4 |

### Sensor Fusion (Cross-Modal Transformer)

**Training Type**: From scratch (requires pretrained modality models)

#### Prerequisites

All modality-specific models must be trained first:

- Optical model checkpoint
- RF model checkpoint
- Radar model checkpoint
- Acoustic model checkpoint

#### Training Strategy

1. **Freeze all modality encoders** - Only train fusion layers
2. **Cache extracted features** - Speeds up training significantly
3. **Modality dropout** - Randomly drop 1-2 modalities during training (20%
   probability)

### Behavioral Analysis (GAT)

**Training Type**: From scratch

#### Data Requirements

Multi-drone trajectory graphs from swarm scenarios:

- Single drone tracks: 50,000
- Multi-drone scenes: 30,000
- Swarm formations: 10,000

### Threat Attribution (XGBoost+NN)

**Training Type**: From scratch (fast, tabular data)

```python
attribution_config = {
    "ensemble_weights": {
        "xgboost": 0.6,
        "neural_network": 0.4,
    },
    "xgboost": {
        "n_estimators": 200,
        "max_depth": 8,
        "learning_rate": 0.1,
        "early_stopping_rounds": 20,
    },
    "neural_network": {
        "architecture": [256, 128, 64],
        "dropout": 0.3,
        "learning_rate": 1e-3,
        "epochs": 100,
    }
}
```

---

## Edge Deployment & Optimization

### Optimization Pipeline

```
PyTorch Model
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ONNX Export    â”‚  torch.onnx.export()
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ONNX Optimize  â”‚  onnxruntime optimizations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TensorRT      â”‚ â”‚   OpenVINO      â”‚ â”‚   TFLite        â”‚
â”‚   (NVIDIA)      â”‚ â”‚   (Intel)       â”‚ â”‚   (Mobile)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                  â”‚
         â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FP16/INT8      â”‚ â”‚  FP16/INT8      â”‚ â”‚  INT8/FP16      â”‚
â”‚  Quantization   â”‚ â”‚  Quantization   â”‚ â”‚  Quantization   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                  â”‚
         â–¼                  â–¼                  â–¼
    Jetson AGX         Intel NUC           Mobile/ARM
```

### Quantization Strategy

| Model    | FP32 Size | FP16 Size | INT8 Size | Accuracy Drop |
| -------- | --------- | --------- | --------- | ------------- |
| Optical  | 350 MB    | 175 MB    | 90 MB     | < 0.5%        |
| RF       | 100 MB    | 50 MB     | 25 MB     | < 0.3%        |
| Radar    | 60 MB     | 30 MB     | 15 MB     | < 0.2%        |
| Acoustic | 350 MB    | 175 MB    | 90 MB     | < 0.5%        |
| Fusion   | 80 MB     | 40 MB     | 20 MB     | < 0.3%        |

### Target Latencies

| Component | GPU (A100) | Edge (Jetson) | Target      |
| --------- | ---------- | ------------- | ----------- |
| Optical   | 35ms       | 80ms          | < 120ms     |
| RF        | 25ms       | 50ms          | < 80ms      |
| Radar     | 18ms       | 35ms          | < 60ms      |
| Acoustic  | 40ms       | 70ms          | < 100ms     |
| Fusion    | 30ms       | 50ms          | < 80ms      |
| **Total** | ~100ms     | ~150ms        | **< 200ms** |

---

## Training Timeline & Resource Requirements

### 16-Week Training Timeline

```
PHASE 1: DATA PREPARATION (Weeks 1-2)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Week 1 â”‚ Optical & RF data collection, labeling, quality validation
Week 2 â”‚ Radar & acoustic data, synthetic augmentation, dataset splits

PHASE 2: INDIVIDUAL MODEL TRAINING (Weeks 3-10)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Week 3 â”‚ Optical Stage 1 (head only)
Week 4 â”‚ Optical Stages 2-3 (progressive unfreezing)
Week 5 â”‚ RF model training (from scratch)
Week 6 â”‚ RF model training continued + validation
Week 7 â”‚ Radar Mamba training (from scratch)
Week 8 â”‚ Radar validation + Acoustic Stage 1
Week 9 â”‚ Acoustic Stages 2-3 (progressive unfreezing)
Week 10â”‚ All individual model validation + checkpointing

PHASE 3: FUSION & BEHAVIORAL MODELS (Weeks 11-13)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Week 11â”‚ Feature extraction caching from all modality models
Week 12â”‚ Cross-modal fusion training
Week 13â”‚ Behavioral GAT training + attribution ensemble

PHASE 4: OPTIMIZATION & VALIDATION (Weeks 14-16)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Week 14â”‚ ONNX export, TensorRT conversion
Week 15â”‚ Edge device benchmarking, quantization tuning
Week 16â”‚ Final validation, documentation, deployment package
```

### Resource Requirements

| Resource      | Specification         | Cost Estimate |
| ------------- | --------------------- | ------------- |
| GPU Compute   | 4Ã— NVIDIA A100 (80GB) | $35,000 cloud |
| Storage       | 10 TB NVMe            | $2,000        |
| Data Labeling | 380,000 samples       | $5,000        |
| Edge Devices  | 2Ã— Jetson AGX Orin    | $3,000        |
| **Total**     |                       | **~$45,000**  |

### Team Requirements

| Role           | Count | Responsibility               |
| -------------- | ----- | ---------------------------- |
| ML Engineer    | 2     | Model training, optimization |
| Data Engineer  | 1     | Pipeline, data quality       |
| MLOps Engineer | 1     | Infrastructure, deployment   |

---

## Validation & Success Criteria

### Model-Level Validation

| Model    | Accuracy Target | Latency Target | Validation Dataset     |
| -------- | --------------- | -------------- | ---------------------- |
| Optical  | > 98%           | < 35ms GPU     | 15,000 held-out images |
| RF       | > 96%           | < 25ms GPU     | 7,500 held-out samples |
| Radar    | > 97%           | < 18ms GPU     | 30,000 held-out tracks |
| Acoustic | > 95%           | < 40ms GPU     | 4,500 held-out clips   |
| Fusion   | > 99%           | < 30ms GPU     | Multi-modal test set   |

### System-Level Validation

| Metric                         | Target  | Validation Method |
| ------------------------------ | ------- | ----------------- |
| End-to-end accuracy            | > 99%   | Field trial data  |
| Total latency                  | < 200ms | Timing benchmarks |
| False positive rate            | < 1%    | Extended testing  |
| Edge deployment                | < 150ms | Jetson benchmarks |
| Degraded mode (missing sensor) | > 95%   | Ablation testing  |

### Validation Checkpoints

```
Week 4  â”‚ âœ“ Optical accuracy > 97%        â†’ Proceed to RF training
Week 6  â”‚ âœ“ RF accuracy > 95%             â†’ Proceed to Radar training
Week 8  â”‚ âœ“ Radar accuracy > 96%          â†’ Proceed to Acoustic training
Week 10 â”‚ âœ“ Acoustic accuracy > 94%       â†’ Proceed to Fusion
Week 13 â”‚ âœ“ Fusion accuracy > 98%         â†’ Proceed to Edge optimization
Week 16 â”‚ âœ“ Edge latency < 150ms          â†’ Ready for deployment
        â”‚ âœ“ All models pass robustness tests
```

---

## Federated Learning Integration

### FLBC Protocol

After initial centralized training, models are deployed for federated learning:

```
Central Server                    Deployment Sites
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Global Model  â”‚ â”€â”€â”€Distributeâ”€â”€â–ºâ”‚ Site A  â”‚  â”‚ Site B  â”‚  â”‚ Site C  â”‚
â”‚   v1.0        â”‚                 â”‚ Local   â”‚  â”‚ Local   â”‚  â”‚ Local   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚ Data    â”‚  â”‚ Data    â”‚  â”‚ Data    â”‚
       â–²                          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â”‚                               â”‚            â”‚            â”‚
       â”‚                               â–¼            â–¼            â–¼
       â”‚                          Local Train   Local Train  Local Train
       â”‚                               â”‚            â”‚            â”‚
       â”‚                               â–¼            â–¼            â–¼
       â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                          â”‚      Blockchain Consensus       â”‚
       â”‚                          â”‚   (Validate + Aggregate)        â”‚
       â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    Aggregated Update
                         â”‚
                         â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Global Model  â”‚
               â”‚   v1.1        â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Continuous Learning Schedule

| Frequency | Activity                                      |
| --------- | --------------------------------------------- |
| Daily     | Local model inference, data collection        |
| Weekly    | Federated learning round (if enough new data) |
| Monthly   | Full model evaluation, performance audit      |
| Quarterly | Major model update consideration              |

---

## Quick Reference Card

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
               PHOENIX ROOIVALK ML TRAINING QUICK REFERENCE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MODEL SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Component     â”‚ Model           â”‚ Training    â”‚ Data      â”‚ Time
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Optical       â”‚ ConvNeXt-Base   â”‚ Fine-tune   â”‚ 100k img  â”‚ 2 weeks
RF            â”‚ CNN+Transformer â”‚ Scratch     â”‚ 50k samp  â”‚ 2 weeks
Radar         â”‚ Mamba-2         â”‚ Scratch     â”‚ 200k trk  â”‚ 1 week
Acoustic      â”‚ BEATs           â”‚ Fine-tune   â”‚ 30k clip  â”‚ 2 weeks
Fusion        â”‚ Cross-Modal TF  â”‚ Scratch     â”‚ Features  â”‚ 1 week
Behavioral    â”‚ GAT+TF          â”‚ Scratch     â”‚ Graphs    â”‚ 1 week
Attribution   â”‚ XGBoost+NN      â”‚ Scratch     â”‚ Tabular   â”‚ 2 days

PROGRESSIVE UNFREEZING (Fine-tuning models)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Stage 1 â”‚ Freeze all, train head      â”‚ LR: 1e-3        â”‚ 5 epochs
Stage 2 â”‚ Unfreeze last 2 stages      â”‚ LR: 1e-5 to 1e-3â”‚ 20 epochs
Stage 3 â”‚ Unfreeze all, differential  â”‚ LR: 1e-7 to 1e-3â”‚ 25+ epochs

KEY HYPERPARAMETERS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Optimizer     â”‚ AdamW (weight_decay=0.01-0.05)
Scheduler     â”‚ CosineAnnealingWarmRestarts or OneCycleLR
Label Smooth  â”‚ 0.1
Gradient Clip â”‚ 1.0
Mixed Prec    â”‚ BF16 or FP16

EDGE DEPLOYMENT
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Export        â”‚ PyTorch â†’ ONNX â†’ TensorRT/OpenVINO
Quantization  â”‚ FP16 (default), INT8 (if accuracy allows)
Target        â”‚ < 150ms total, < 4GB GPU memory

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Document Control

| Version | Date | Author  | Changes                                        |
| ------- | ---- | ------- | ---------------------------------------------- |
| 1.0     | 2025 | AI Team | Initial draft                                  |
| 2.0     | 2025 | AI Team | Added progressive unfreezing detail, finalized |

---

_This document is the authoritative reference for ML model training in the
Phoenix Rooivalk project. All training activities should follow these guidelines
to ensure consistency and reproducibility. Â© 2025 Phoenix Rooivalk. All rights
reserved._
